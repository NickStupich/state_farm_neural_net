import numpy as np
import pylab
import sys

if len(sys.argv) > 1:
	print('reading data from file: %s' % sys.argv[1])
	s = open(sys.argv[1]).readlines()
	s = ''.join(filter(lambda x: not '\b' in x, s))
else:
	print('static test data')
	s = """cat vgg16log4.txt 
	encoded data filename: vgg16_encoder1/vgg_encoded_test_connected-False.npy
	Restore data from pickle........
	encoded test data shape: (79726, 25088)
	test id length: 79726
	Restore train from cache!
	Restore data from pickle........
	Train shape: (22424, 3, 224, 224)
	22424 train samples
	encoded data filename: vgg16_encoder1/vgg_encoded_connected-False.npy
	getting encoded data from file
	train encoded shape: (22424, 25088)
	train encoded type: float32
	test encoded shape: (79726, 25088)
	____________________________________________________________________________________________________
	Layer (type)                       Output Shape        Param #     Connected to                     
	====================================================================================================
	dense_1 (Dense)                    (None, 4096)        102764544   dense_input_1[0][0]              
	____________________________________________________________________________________________________
	dropout_1 (Dropout)                (None, 4096)        0           dense_1[0][0]                    
	____________________________________________________________________________________________________
	dense_2 (Dense)                    (None, 4096)        16781312    dropout_1[0][0]                  
	____________________________________________________________________________________________________
	dropout_2 (Dropout)                (None, 4096)        0           dense_2[0][0]                    
	____________________________________________________________________________________________________
	dense_3 (Dense)                    (None, 10)          40970       dropout_2[0][0]                  
	====================================================================================================
	Total params: 119586826
	____________________________________________________________________________________________________
	Start KFold number 1 from 13
	Split train:  20547 20547
	Split valid:  1877 1877
	Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p026', 'p035', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p024', 'p039']
	Training keras model...
	Train on 20547 samples, validate on 1877 samples
	Epoch 1/100
	20547/20547 [==============================] - 115s - loss: 2.4994 - acc: 0.2471 - val_loss: 1.7669 - val_acc: 0.4166
	Epoch 2/100
	20547/20547 [==============================] - 116s - loss: 1.4695 - acc: 0.5010 - val_loss: 1.4714 - val_acc: 0.5328
	Epoch 3/100
	20547/20547 [==============================] - 116s - loss: 1.0325 - acc: 0.6580 - val_loss: 1.3123 - val_acc: 0.5599
	Epoch 4/100
	20547/20547 [==============================] - 117s - loss: 0.7568 - acc: 0.7606 - val_loss: 1.1929 - val_acc: 0.5946
	Epoch 5/100
	20547/20547 [==============================] - 117s - loss: 0.5830 - acc: 0.8227 - val_loss: 1.1316 - val_acc: 0.6175
	Epoch 6/100
	20547/20547 [==============================] - 117s - loss: 0.4709 - acc: 0.8607 - val_loss: 1.0876 - val_acc: 0.6313
	Epoch 7/100
	20547/20547 [==============================] - 116s - loss: 0.3940 - acc: 0.8821 - val_loss: 1.0862 - val_acc: 0.6308
	Epoch 8/100
	20547/20547 [==============================] - 116s - loss: 0.3263 - acc: 0.9040 - val_loss: 1.0318 - val_acc: 0.6569
	Epoch 9/100
	20547/20547 [==============================] - 117s - loss: 0.2878 - acc: 0.9168 - val_loss: 1.0223 - val_acc: 0.6558
	Epoch 10/100
	20547/20547 [==============================] - 116s - loss: 0.2544 - acc: 0.9272 - val_loss: 1.0376 - val_acc: 0.6558
	Epoch 11/100
	20547/20547 [==============================] - 117s - loss: 0.2283 - acc: 0.9349 - val_loss: 1.0210 - val_acc: 0.6606
	Epoch 12/100
	20547/20547 [==============================] - 117s - loss: 0.2005 - acc: 0.9445 - val_loss: 0.9846 - val_acc: 0.6729
	Epoch 13/100
	20547/20547 [==============================] - 117s - loss: 0.1834 - acc: 0.9496 - val_loss: 1.0137 - val_acc: 0.6558
	Epoch 14/100
	20547/20547 [==============================] - 117s - loss: 0.1665 - acc: 0.9550 - val_loss: 0.9903 - val_acc: 0.6766
	Epoch 15/100
	20547/20547 [==============================] - 117s - loss: 0.1509 - acc: 0.9589 - val_loss: 1.0124 - val_acc: 0.6638
	Epoch 16/100
	20547/20547 [==============================] - 117s - loss: 0.1456 - acc: 0.9597 - val_loss: 0.9735 - val_acc: 0.6798
	Epoch 17/100
	20547/20547 [==============================] - 117s - loss: 0.1318 - acc: 0.9641 - val_loss: 1.0006 - val_acc: 0.6702
	Epoch 18/100
	20547/20547 [==============================] - 117s - loss: 0.1250 - acc: 0.9665 - val_loss: 0.9856 - val_acc: 0.6771
	Epoch 19/100
	20547/20547 [==============================] - 118s - loss: 0.1158 - acc: 0.9700 - val_loss: 0.9673 - val_acc: 0.6873
	Epoch 20/100
	20547/20547 [==============================] - 116s - loss: 0.1059 - acc: 0.9728 - val_loss: 0.9814 - val_acc: 0.6814
	Epoch 21/100
	20547/20547 [==============================] - 117s - loss: 0.1037 - acc: 0.9731 - val_loss: 1.0000 - val_acc: 0.6841
	Epoch 22/100
	20547/20547 [==============================] - 117s - loss: 0.0971 - acc: 0.9750 - val_loss: 0.9693 - val_acc: 0.6947
	Epoch 23/100
	20547/20547 [==============================] - 117s - loss: 0.0899 - acc: 0.9775 - val_loss: 0.9862 - val_acc: 0.6889
	Epoch 24/100
	20547/20547 [==============================] - 117s - loss: 0.0873 - acc: 0.9772 - val_loss: 1.0029 - val_acc: 0.6915
	Epoch 25/100
	20547/20547 [==============================] - 117s - loss: 0.0831 - acc: 0.9786 - val_loss: 0.9726 - val_acc: 0.6937
	Epoch 26/100
	20547/20547 [==============================] - 117s - loss: 0.0785 - acc: 0.9787 - val_loss: 0.9844 - val_acc: 0.6921
	Epoch 27/100
	20547/20547 [==============================] - 117s - loss: 0.0772 - acc: 0.9795 - val_loss: 0.9845 - val_acc: 0.6931
	Epoch 28/100
	20547/20547 [==============================] - 117s - loss: 0.0702 - acc: 0.9826 - val_loss: 0.9894 - val_acc: 0.6937
	Epoch 29/100
	20547/20547 [==============================] - 117s - loss: 0.0663 - acc: 0.9834 - val_loss: 0.9695 - val_acc: 0.7011
	Epoch 30/100
	20547/20547 [==============================] - 118s - loss: 0.0662 - acc: 0.9825 - val_loss: 0.9618 - val_acc: 0.7032
	Epoch 31/100
	20547/20547 [==============================] - 117s - loss: 0.0626 - acc: 0.9835 - val_loss: 0.9730 - val_acc: 0.7022
	Epoch 32/100
	20547/20547 [==============================] - 121s - loss: 0.0620 - acc: 0.9834 - val_loss: 0.9626 - val_acc: 0.7043
	Epoch 33/100
	20547/20547 [==============================] - 121s - loss: 0.0555 - acc: 0.9854 - val_loss: 0.9646 - val_acc: 0.7027
	Epoch 34/100
	20547/20547 [==============================] - 121s - loss: 0.0572 - acc: 0.9852 - val_loss: 0.9648 - val_acc: 0.7054
	Epoch 35/100
	20547/20547 [==============================] - 121s - loss: 0.0534 - acc: 0.9864 - val_loss: 0.9826 - val_acc: 0.7038
	Epoch 36/100
	20547/20547 [==============================] - 121s - loss: 0.0543 - acc: 0.9861 - val_loss: 0.9623 - val_acc: 0.7086
	Epoch 37/100
	20547/20547 [==============================] - 121s - loss: 0.0500 - acc: 0.9873 - val_loss: 0.9705 - val_acc: 0.6990
	Epoch 38/100
	20547/20547 [==============================] - 120s - loss: 0.0472 - acc: 0.9880 - val_loss: 0.9851 - val_acc: 0.6979
	Epoch 39/100
	20547/20547 [==============================] - 121s - loss: 0.0485 - acc: 0.9872 - val_loss: 0.9774 - val_acc: 0.7006
	Epoch 40/100
	20547/20547 [==============================] - 121s - loss: 0.0455 - acc: 0.9895 - val_loss: 0.9626 - val_acc: 0.7017
	Epoch 41/100
	20547/20547 [==============================] - 122s - loss: 0.0430 - acc: 0.9898 - val_loss: 0.9511 - val_acc: 0.7128
	Epoch 42/100
	20547/20547 [==============================] - 122s - loss: 0.0430 - acc: 0.9893 - val_loss: 0.9494 - val_acc: 0.7091
	Epoch 43/100
	20547/20547 [==============================] - 121s - loss: 0.0418 - acc: 0.9892 - val_loss: 0.9581 - val_acc: 0.7080
	Epoch 44/100
	20547/20547 [==============================] - 121s - loss: 0.0391 - acc: 0.9908 - val_loss: 0.9498 - val_acc: 0.7139
	Epoch 45/100
	20547/20547 [==============================] - 121s - loss: 0.0381 - acc: 0.9909 - val_loss: 0.9657 - val_acc: 0.7102
	Epoch 46/100
	20547/20547 [==============================] - 121s - loss: 0.0397 - acc: 0.9899 - val_loss: 0.9710 - val_acc: 0.7107
	Epoch 47/100
	20547/20547 [==============================] - 121s - loss: 0.0378 - acc: 0.9906 - val_loss: 0.9566 - val_acc: 0.7107
	Epoch 48/100
	20547/20547 [==============================] - 121s - loss: 0.0364 - acc: 0.9911 - val_loss: 0.9528 - val_acc: 0.7160
	Epoch 49/100
	20547/20547 [==============================] - 121s - loss: 0.0356 - acc: 0.9911 - val_loss: 0.9624 - val_acc: 0.7134
	Epoch 50/100
	20547/20547 [==============================] - 121s - loss: 0.0334 - acc: 0.9918 - val_loss: 0.9619 - val_acc: 0.7118
	Epoch 51/100
	20547/20547 [==============================] - 121s - loss: 0.0339 - acc: 0.9917 - val_loss: 0.9592 - val_acc: 0.7112
	Epoch 52/100
	20547/20547 [==============================] - 121s - loss: 0.0323 - acc: 0.9924 - val_loss: 0.9670 - val_acc: 0.7166
	Epoch 53/100
	20547/20547 [==============================] - 121s - loss: 0.0310 - acc: 0.9926 - val_loss: 0.9637 - val_acc: 0.7139
	1877/1877 [==============================] - 4s     
	79726/79726 [==============================] - 180s     
	Score log_loss:  0.949440797883
	Start KFold number 2 from 13
	Split train:  20882 20882
	Split valid:  1542 1542
	Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p075', 'p081']
	Test drivers:  ['p026', 'p072']
	Training keras model...
	Train on 20882 samples, validate on 1542 samples
	Epoch 1/100
	20882/20882 [==============================] - 122s - loss: 2.2932 - acc: 0.2996 - val_loss: 1.5298 - val_acc: 0.5564
	Epoch 2/100
	20882/20882 [==============================] - 123s - loss: 1.2854 - acc: 0.5683 - val_loss: 1.2522 - val_acc: 0.6615
	Epoch 3/100
	20882/20882 [==============================] - 123s - loss: 0.8785 - acc: 0.7148 - val_loss: 1.1050 - val_acc: 0.6965
	Epoch 4/100
	20882/20882 [==============================] - 122s - loss: 0.6410 - acc: 0.7990 - val_loss: 1.0133 - val_acc: 0.7095
	Epoch 5/100
	20882/20882 [==============================] - 123s - loss: 0.4973 - acc: 0.8485 - val_loss: 0.9425 - val_acc: 0.7244
	Epoch 6/100
	20882/20882 [==============================] - 123s - loss: 0.4078 - acc: 0.8798 - val_loss: 0.8912 - val_acc: 0.7425
	Epoch 7/100
	20882/20882 [==============================] - 122s - loss: 0.3320 - acc: 0.9028 - val_loss: 0.8875 - val_acc: 0.7374
	Epoch 8/100
	20882/20882 [==============================] - 123s - loss: 0.2867 - acc: 0.9170 - val_loss: 0.8571 - val_acc: 0.7458
	Epoch 9/100
	20882/20882 [==============================] - 122s - loss: 0.2505 - acc: 0.9281 - val_loss: 0.8422 - val_acc: 0.7568
	Epoch 10/100
	20882/20882 [==============================] - 122s - loss: 0.2128 - acc: 0.9397 - val_loss: 0.8262 - val_acc: 0.7639
	Epoch 11/100
	20882/20882 [==============================] - 123s - loss: 0.2013 - acc: 0.9411 - val_loss: 0.8207 - val_acc: 0.7646
	Epoch 12/100
	20882/20882 [==============================] - 123s - loss: 0.1811 - acc: 0.9493 - val_loss: 0.8010 - val_acc: 0.7711
	Epoch 13/100
	20882/20882 [==============================] - 122s - loss: 0.1596 - acc: 0.9566 - val_loss: 0.8029 - val_acc: 0.7711
	Epoch 14/100
	20882/20882 [==============================] - 122s - loss: 0.1474 - acc: 0.9601 - val_loss: 0.7981 - val_acc: 0.7750
	Epoch 15/100
	20882/20882 [==============================] - 122s - loss: 0.1399 - acc: 0.9622 - val_loss: 0.7970 - val_acc: 0.7737
	Epoch 16/100
	20882/20882 [==============================] - 122s - loss: 0.1294 - acc: 0.9638 - val_loss: 0.8090 - val_acc: 0.7711
	Epoch 17/100
	20882/20882 [==============================] - 122s - loss: 0.1201 - acc: 0.9679 - val_loss: 0.7910 - val_acc: 0.7763
	Epoch 18/100
	20882/20882 [==============================] - 123s - loss: 0.1091 - acc: 0.9708 - val_loss: 0.7808 - val_acc: 0.7827
	Epoch 19/100
	20882/20882 [==============================] - 121s - loss: 0.1070 - acc: 0.9719 - val_loss: 0.7832 - val_acc: 0.7827
	Epoch 20/100
	20882/20882 [==============================] - 122s - loss: 0.0977 - acc: 0.9741 - val_loss: 0.7850 - val_acc: 0.7808
	Epoch 21/100
	20882/20882 [==============================] - 122s - loss: 0.0929 - acc: 0.9766 - val_loss: 0.7822 - val_acc: 0.7853
	Epoch 22/100
	20882/20882 [==============================] - 122s - loss: 0.0869 - acc: 0.9768 - val_loss: 0.7805 - val_acc: 0.7912
	Epoch 23/100
	20882/20882 [==============================] - 122s - loss: 0.0820 - acc: 0.9789 - val_loss: 0.7799 - val_acc: 0.7892
	Epoch 24/100
	20882/20882 [==============================] - 122s - loss: 0.0810 - acc: 0.9783 - val_loss: 0.7916 - val_acc: 0.7873
	Epoch 25/100
	20882/20882 [==============================] - 122s - loss: 0.0747 - acc: 0.9806 - val_loss: 0.8060 - val_acc: 0.7840
	Epoch 26/100
	20882/20882 [==============================] - 121s - loss: 0.0716 - acc: 0.9817 - val_loss: 0.7890 - val_acc: 0.7925
	Epoch 27/100
	20882/20882 [==============================] - 121s - loss: 0.0686 - acc: 0.9831 - val_loss: 0.7850 - val_acc: 0.7944
	Epoch 28/100
	20882/20882 [==============================] - 122s - loss: 0.0640 - acc: 0.9843 - val_loss: 0.7997 - val_acc: 0.7873
	Epoch 29/100
	20882/20882 [==============================] - 123s - loss: 0.0609 - acc: 0.9849 - val_loss: 0.7759 - val_acc: 0.7964
	Epoch 30/100
	20882/20882 [==============================] - 122s - loss: 0.0603 - acc: 0.9855 - val_loss: 0.7950 - val_acc: 0.7925
	Epoch 31/100
	20882/20882 [==============================] - 122s - loss: 0.0582 - acc: 0.9847 - val_loss: 0.7934 - val_acc: 0.7925
	Epoch 32/100
	20882/20882 [==============================] - 122s - loss: 0.0546 - acc: 0.9865 - val_loss: 0.7986 - val_acc: 0.7918
	Epoch 33/100
	20882/20882 [==============================] - 122s - loss: 0.0551 - acc: 0.9859 - val_loss: 0.7981 - val_acc: 0.7938
	Epoch 34/100
	20882/20882 [==============================] - 122s - loss: 0.0508 - acc: 0.9866 - val_loss: 0.7869 - val_acc: 0.7951
	Epoch 35/100
	20882/20882 [==============================] - 122s - loss: 0.0494 - acc: 0.9877 - val_loss: 0.7923 - val_acc: 0.7951
	Epoch 36/100
	20882/20882 [==============================] - 122s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.7954 - val_acc: 0.7931
	Epoch 37/100
	20882/20882 [==============================] - 122s - loss: 0.0452 - acc: 0.9895 - val_loss: 0.7904 - val_acc: 0.7938
	Epoch 38/100
	20882/20882 [==============================] - 122s - loss: 0.0436 - acc: 0.9885 - val_loss: 0.7887 - val_acc: 0.7964
	Epoch 39/100
	20882/20882 [==============================] - 122s - loss: 0.0414 - acc: 0.9903 - val_loss: 0.7918 - val_acc: 0.7957
	Epoch 40/100
	20882/20882 [==============================] - 122s - loss: 0.0422 - acc: 0.9893 - val_loss: 0.7893 - val_acc: 0.7925
	1542/1542 [==============================] - 3s     
	79726/79726 [==============================] - 177s     
	Score log_loss:  0.775912121687
	Start KFold number 3 from 13
	Split train:  20792 20792
	Split valid:  1632 1632
	Train drivers:  ['p002', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p012', 'p061']
	Training keras model...
	Train on 20792 samples, validate on 1632 samples
	Epoch 1/100
	20792/20792 [==============================] - 122s - loss: 2.1089 - acc: 0.3445 - val_loss: 1.2633 - val_acc: 0.6250
	Epoch 2/100
	20792/20792 [==============================] - 122s - loss: 1.1668 - acc: 0.6087 - val_loss: 1.0178 - val_acc: 0.6900
	Epoch 3/100
	20792/20792 [==============================] - 122s - loss: 0.7925 - acc: 0.7427 - val_loss: 0.8744 - val_acc: 0.7273
	Epoch 4/100
	20792/20792 [==============================] - 122s - loss: 0.5902 - acc: 0.8126 - val_loss: 0.7836 - val_acc: 0.7690
	Epoch 5/100
	20792/20792 [==============================] - 122s - loss: 0.4620 - acc: 0.8607 - val_loss: 0.7229 - val_acc: 0.7825
	Epoch 6/100
	20792/20792 [==============================] - 121s - loss: 0.3760 - acc: 0.8875 - val_loss: 0.7010 - val_acc: 0.7825
	Epoch 7/100
	20792/20792 [==============================] - 122s - loss: 0.3143 - acc: 0.9060 - val_loss: 0.6674 - val_acc: 0.7886
	Epoch 8/100
	20792/20792 [==============================] - 122s - loss: 0.2653 - acc: 0.9222 - val_loss: 0.6607 - val_acc: 0.7904
	Epoch 9/100
	20792/20792 [==============================] - 122s - loss: 0.2275 - acc: 0.9335 - val_loss: 0.6340 - val_acc: 0.7972
	Epoch 10/100
	20792/20792 [==============================] - 122s - loss: 0.2070 - acc: 0.9418 - val_loss: 0.6155 - val_acc: 0.8002
	Epoch 11/100
	20792/20792 [==============================] - 122s - loss: 0.1877 - acc: 0.9474 - val_loss: 0.6089 - val_acc: 0.8058
	Epoch 12/100
	20792/20792 [==============================] - 122s - loss: 0.1675 - acc: 0.9532 - val_loss: 0.6037 - val_acc: 0.8058
	Epoch 13/100
	20792/20792 [==============================] - 122s - loss: 0.1529 - acc: 0.9560 - val_loss: 0.5913 - val_acc: 0.8045
	Epoch 14/100
	20792/20792 [==============================] - 122s - loss: 0.1375 - acc: 0.9620 - val_loss: 0.5743 - val_acc: 0.8137
	Epoch 15/100
	20792/20792 [==============================] - 122s - loss: 0.1295 - acc: 0.9640 - val_loss: 0.5616 - val_acc: 0.8217
	Epoch 16/100
	20792/20792 [==============================] - 122s - loss: 0.1175 - acc: 0.9693 - val_loss: 0.5597 - val_acc: 0.8168
	Epoch 17/100
	20792/20792 [==============================] - 121s - loss: 0.1143 - acc: 0.9682 - val_loss: 0.5615 - val_acc: 0.8186
	Epoch 18/100
	20792/20792 [==============================] - 122s - loss: 0.1035 - acc: 0.9723 - val_loss: 0.5470 - val_acc: 0.8211
	Epoch 19/100
	20792/20792 [==============================] - 122s - loss: 0.0943 - acc: 0.9760 - val_loss: 0.5372 - val_acc: 0.8241
	Epoch 20/100
	20792/20792 [==============================] - 122s - loss: 0.0931 - acc: 0.9760 - val_loss: 0.5367 - val_acc: 0.8248
	Epoch 21/100
	20792/20792 [==============================] - 122s - loss: 0.0887 - acc: 0.9755 - val_loss: 0.5337 - val_acc: 0.8260
	Epoch 22/100
	20792/20792 [==============================] - 122s - loss: 0.0816 - acc: 0.9790 - val_loss: 0.5208 - val_acc: 0.8303
	Epoch 23/100
	20792/20792 [==============================] - 122s - loss: 0.0779 - acc: 0.9811 - val_loss: 0.5318 - val_acc: 0.8278
	Epoch 24/100
	20792/20792 [==============================] - 121s - loss: 0.0733 - acc: 0.9814 - val_loss: 0.5289 - val_acc: 0.8254
	Epoch 25/100
	20792/20792 [==============================] - 121s - loss: 0.0710 - acc: 0.9814 - val_loss: 0.5278 - val_acc: 0.8297
	Epoch 26/100
	20792/20792 [==============================] - 122s - loss: 0.0676 - acc: 0.9828 - val_loss: 0.5159 - val_acc: 0.8284
	Epoch 27/100
	20792/20792 [==============================] - 122s - loss: 0.0642 - acc: 0.9842 - val_loss: 0.5151 - val_acc: 0.8321
	Epoch 28/100
	20792/20792 [==============================] - 122s - loss: 0.0632 - acc: 0.9837 - val_loss: 0.5179 - val_acc: 0.8284
	Epoch 29/100
	20792/20792 [==============================] - 122s - loss: 0.0584 - acc: 0.9851 - val_loss: 0.5173 - val_acc: 0.8309
	Epoch 30/100
	20792/20792 [==============================] - 122s - loss: 0.0554 - acc: 0.9868 - val_loss: 0.5160 - val_acc: 0.8321
	Epoch 31/100
	20792/20792 [==============================] - 122s - loss: 0.0533 - acc: 0.9866 - val_loss: 0.5063 - val_acc: 0.8321
	Epoch 32/100
	20792/20792 [==============================] - 121s - loss: 0.0528 - acc: 0.9865 - val_loss: 0.5096 - val_acc: 0.8346
	Epoch 33/100
	20792/20792 [==============================] - 121s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.5210 - val_acc: 0.8297
	Epoch 34/100
	20792/20792 [==============================] - 121s - loss: 0.0500 - acc: 0.9864 - val_loss: 0.5211 - val_acc: 0.8272
	Epoch 35/100
	20792/20792 [==============================] - 122s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.5095 - val_acc: 0.8290
	Epoch 36/100
	20792/20792 [==============================] - 122s - loss: 0.0442 - acc: 0.9892 - val_loss: 0.5136 - val_acc: 0.8315
	Epoch 37/100
	20792/20792 [==============================] - 121s - loss: 0.0437 - acc: 0.9899 - val_loss: 0.5108 - val_acc: 0.8315
	Epoch 38/100
	20792/20792 [==============================] - 122s - loss: 0.0420 - acc: 0.9903 - val_loss: 0.5105 - val_acc: 0.8315
	Epoch 39/100
	20792/20792 [==============================] - 122s - loss: 0.0423 - acc: 0.9888 - val_loss: 0.5111 - val_acc: 0.8321
	Epoch 40/100
	20792/20792 [==============================] - 122s - loss: 0.0403 - acc: 0.9897 - val_loss: 0.5025 - val_acc: 0.8315
	Epoch 41/100
	20792/20792 [==============================] - 121s - loss: 0.0373 - acc: 0.9907 - val_loss: 0.5125 - val_acc: 0.8309
	Epoch 42/100
	20792/20792 [==============================] - 121s - loss: 0.0392 - acc: 0.9899 - val_loss: 0.5097 - val_acc: 0.8278
	Epoch 43/100
	20792/20792 [==============================] - 122s - loss: 0.0374 - acc: 0.9905 - val_loss: 0.4989 - val_acc: 0.8333
	Epoch 44/100
	20792/20792 [==============================] - 121s - loss: 0.0327 - acc: 0.9920 - val_loss: 0.5047 - val_acc: 0.8339
	Epoch 45/100
	20792/20792 [==============================] - 122s - loss: 0.0343 - acc: 0.9912 - val_loss: 0.5034 - val_acc: 0.8352
	Epoch 46/100
	20792/20792 [==============================] - 122s - loss: 0.0352 - acc: 0.9907 - val_loss: 0.5064 - val_acc: 0.8370
	Epoch 47/100
	20792/20792 [==============================] - 121s - loss: 0.0316 - acc: 0.9923 - val_loss: 0.5101 - val_acc: 0.8321
	Epoch 48/100
	20792/20792 [==============================] - 122s - loss: 0.0309 - acc: 0.9920 - val_loss: 0.5085 - val_acc: 0.8315
	Epoch 49/100
	20792/20792 [==============================] - 121s - loss: 0.0301 - acc: 0.9924 - val_loss: 0.5021 - val_acc: 0.8376
	Epoch 50/100
	20792/20792 [==============================] - 121s - loss: 0.0313 - acc: 0.9924 - val_loss: 0.5023 - val_acc: 0.8346
	Epoch 51/100
	20792/20792 [==============================] - 122s - loss: 0.0281 - acc: 0.9931 - val_loss: 0.4914 - val_acc: 0.8425
	Epoch 52/100
	20792/20792 [==============================] - 121s - loss: 0.0273 - acc: 0.9938 - val_loss: 0.4990 - val_acc: 0.8382
	Epoch 53/100
	20792/20792 [==============================] - 121s - loss: 0.0269 - acc: 0.9937 - val_loss: 0.5020 - val_acc: 0.8395
	Epoch 54/100
	20792/20792 [==============================] - 122s - loss: 0.0280 - acc: 0.9934 - val_loss: 0.4948 - val_acc: 0.8382
	Epoch 55/100
	20792/20792 [==============================] - 122s - loss: 0.0246 - acc: 0.9945 - val_loss: 0.4946 - val_acc: 0.8413
	Epoch 56/100
	20792/20792 [==============================] - 122s - loss: 0.0254 - acc: 0.9944 - val_loss: 0.4948 - val_acc: 0.8395
	Epoch 57/100
	20792/20792 [==============================] - 122s - loss: 0.0249 - acc: 0.9941 - val_loss: 0.4888 - val_acc: 0.8419
	Epoch 58/100
	20792/20792 [==============================] - 122s - loss: 0.0237 - acc: 0.9937 - val_loss: 0.4814 - val_acc: 0.8401
	Epoch 59/100
	20792/20792 [==============================] - 120s - loss: 0.0233 - acc: 0.9946 - val_loss: 0.4884 - val_acc: 0.8382
	Epoch 60/100
	20792/20792 [==============================] - 121s - loss: 0.0242 - acc: 0.9945 - val_loss: 0.4879 - val_acc: 0.8388
	Epoch 61/100
	20792/20792 [==============================] - 122s - loss: 0.0225 - acc: 0.9950 - val_loss: 0.4887 - val_acc: 0.8407
	Epoch 62/100
	20792/20792 [==============================] - 121s - loss: 0.0226 - acc: 0.9945 - val_loss: 0.4888 - val_acc: 0.8401
	Epoch 63/100
	20792/20792 [==============================] - 122s - loss: 0.0228 - acc: 0.9946 - val_loss: 0.4931 - val_acc: 0.8388
	Epoch 64/100
	20792/20792 [==============================] - 122s - loss: 0.0214 - acc: 0.9952 - val_loss: 0.4911 - val_acc: 0.8456
	Epoch 65/100
	20792/20792 [==============================] - 122s - loss: 0.0209 - acc: 0.9950 - val_loss: 0.4793 - val_acc: 0.8462
	Epoch 66/100
	20792/20792 [==============================] - 121s - loss: 0.0208 - acc: 0.9950 - val_loss: 0.4900 - val_acc: 0.8407
	Epoch 67/100
	20792/20792 [==============================] - 121s - loss: 0.0196 - acc: 0.9957 - val_loss: 0.4885 - val_acc: 0.8425
	Epoch 68/100
	20792/20792 [==============================] - 122s - loss: 0.0191 - acc: 0.9957 - val_loss: 0.4891 - val_acc: 0.8431
	Epoch 69/100
	20792/20792 [==============================] - 121s - loss: 0.0192 - acc: 0.9957 - val_loss: 0.4877 - val_acc: 0.8444
	Epoch 70/100
	20792/20792 [==============================] - 121s - loss: 0.0192 - acc: 0.9958 - val_loss: 0.4853 - val_acc: 0.8444
	Epoch 71/100
	20792/20792 [==============================] - 122s - loss: 0.0189 - acc: 0.9959 - val_loss: 0.4853 - val_acc: 0.8450
	Epoch 72/100
	20792/20792 [==============================] - 121s - loss: 0.0181 - acc: 0.9956 - val_loss: 0.4845 - val_acc: 0.8450
	Epoch 73/100
	20792/20792 [==============================] - 122s - loss: 0.0175 - acc: 0.9962 - val_loss: 0.4804 - val_acc: 0.8474
	Epoch 74/100
	20792/20792 [==============================] - 122s - loss: 0.0178 - acc: 0.9958 - val_loss: 0.4845 - val_acc: 0.8456
	Epoch 75/100
	20792/20792 [==============================] - 121s - loss: 0.0172 - acc: 0.9964 - val_loss: 0.4855 - val_acc: 0.8480
	Epoch 76/100
	20792/20792 [==============================] - 122s - loss: 0.0185 - acc: 0.9958 - val_loss: 0.4844 - val_acc: 0.8456
	1632/1632 [==============================] - 3s     
	79726/79726 [==============================] - 178s     
	Score log_loss:  0.479333944727
	Start KFold number 4 from 13
	Split train:  20754 20754
	Split valid:  1670 1670
	Train drivers:  ['p002', 'p012', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p014', 'p056']
	Training keras model...
	Train on 20754 samples, validate on 1670 samples
	Epoch 1/100
	20754/20754 [==============================] - 121s - loss: 1.9377 - acc: 0.3912 - val_loss: 1.1151 - val_acc: 0.7108
	Epoch 2/100
	20754/20754 [==============================] - 122s - loss: 1.0649 - acc: 0.6431 - val_loss: 0.8851 - val_acc: 0.7778
	Epoch 3/100
	20754/20754 [==============================] - 122s - loss: 0.7214 - acc: 0.7668 - val_loss: 0.7656 - val_acc: 0.7952
	Epoch 4/100
	20754/20754 [==============================] - 121s - loss: 0.5390 - acc: 0.8293 - val_loss: 0.6799 - val_acc: 0.8222
	Epoch 5/100
	20754/20754 [==============================] - 121s - loss: 0.4182 - acc: 0.8699 - val_loss: 0.6218 - val_acc: 0.8353
	Epoch 6/100
	20754/20754 [==============================] - 121s - loss: 0.3483 - acc: 0.8939 - val_loss: 0.5998 - val_acc: 0.8234
	Epoch 7/100
	20754/20754 [==============================] - 121s - loss: 0.2858 - acc: 0.9160 - val_loss: 0.5852 - val_acc: 0.8210
	Epoch 8/100
	20754/20754 [==============================] - 121s - loss: 0.2523 - acc: 0.9257 - val_loss: 0.5566 - val_acc: 0.8287
	Epoch 9/100
	20754/20754 [==============================] - 121s - loss: 0.2166 - acc: 0.9387 - val_loss: 0.5493 - val_acc: 0.8323
	Epoch 10/100
	20754/20754 [==============================] - 121s - loss: 0.1963 - acc: 0.9448 - val_loss: 0.5434 - val_acc: 0.8132
	Epoch 11/100
	20754/20754 [==============================] - 121s - loss: 0.1773 - acc: 0.9492 - val_loss: 0.5193 - val_acc: 0.8323
	Epoch 12/100
	20754/20754 [==============================] - 121s - loss: 0.1642 - acc: 0.9525 - val_loss: 0.5011 - val_acc: 0.8377
	Epoch 13/100
	20754/20754 [==============================] - 121s - loss: 0.1420 - acc: 0.9605 - val_loss: 0.4992 - val_acc: 0.8335
	Epoch 14/100
	20754/20754 [==============================] - 121s - loss: 0.1311 - acc: 0.9625 - val_loss: 0.4922 - val_acc: 0.8365
	Epoch 15/100
	20754/20754 [==============================] - 121s - loss: 0.1252 - acc: 0.9654 - val_loss: 0.4885 - val_acc: 0.8293
	Epoch 16/100
	20754/20754 [==============================] - 121s - loss: 0.1144 - acc: 0.9691 - val_loss: 0.4846 - val_acc: 0.8353
	Epoch 17/100
	20754/20754 [==============================] - 121s - loss: 0.1105 - acc: 0.9695 - val_loss: 0.4779 - val_acc: 0.8335
	Epoch 18/100
	20754/20754 [==============================] - 121s - loss: 0.1021 - acc: 0.9718 - val_loss: 0.4725 - val_acc: 0.8305
	Epoch 19/100
	20754/20754 [==============================] - 121s - loss: 0.0934 - acc: 0.9744 - val_loss: 0.4663 - val_acc: 0.8407
	Epoch 20/100
	20754/20754 [==============================] - 121s - loss: 0.0924 - acc: 0.9750 - val_loss: 0.4710 - val_acc: 0.8359
	Epoch 21/100
	20754/20754 [==============================] - 121s - loss: 0.0840 - acc: 0.9771 - val_loss: 0.4697 - val_acc: 0.8389
	Epoch 22/100
	20754/20754 [==============================] - 121s - loss: 0.0793 - acc: 0.9792 - val_loss: 0.4618 - val_acc: 0.8383
	Epoch 23/100
	20754/20754 [==============================] - 121s - loss: 0.0761 - acc: 0.9800 - val_loss: 0.4464 - val_acc: 0.8479
	Epoch 24/100
	20754/20754 [==============================] - 120s - loss: 0.0718 - acc: 0.9807 - val_loss: 0.4530 - val_acc: 0.8425
	Epoch 25/100
	20754/20754 [==============================] - 120s - loss: 0.0694 - acc: 0.9820 - val_loss: 0.4598 - val_acc: 0.8389
	Epoch 26/100
	20754/20754 [==============================] - 121s - loss: 0.0653 - acc: 0.9821 - val_loss: 0.4532 - val_acc: 0.8395
	Epoch 27/100
	20754/20754 [==============================] - 120s - loss: 0.0623 - acc: 0.9844 - val_loss: 0.4587 - val_acc: 0.8389
	Epoch 28/100
	20754/20754 [==============================] - 121s - loss: 0.0623 - acc: 0.9828 - val_loss: 0.4576 - val_acc: 0.8389
	Epoch 29/100
	20754/20754 [==============================] - 121s - loss: 0.0601 - acc: 0.9835 - val_loss: 0.4535 - val_acc: 0.8407
	Epoch 30/100
	20754/20754 [==============================] - 121s - loss: 0.0565 - acc: 0.9849 - val_loss: 0.4487 - val_acc: 0.8485
	Epoch 31/100
	20754/20754 [==============================] - 121s - loss: 0.0535 - acc: 0.9868 - val_loss: 0.4454 - val_acc: 0.8479
	Epoch 32/100
	20754/20754 [==============================] - 121s - loss: 0.0526 - acc: 0.9873 - val_loss: 0.4390 - val_acc: 0.8521
	Epoch 33/100
	20754/20754 [==============================] - 121s - loss: 0.0483 - acc: 0.9879 - val_loss: 0.4438 - val_acc: 0.8461
	Epoch 34/100
	20754/20754 [==============================] - 121s - loss: 0.0476 - acc: 0.9881 - val_loss: 0.4382 - val_acc: 0.8479
	Epoch 35/100
	20754/20754 [==============================] - 121s - loss: 0.0467 - acc: 0.9876 - val_loss: 0.4464 - val_acc: 0.8419
	Epoch 36/100
	20754/20754 [==============================] - 121s - loss: 0.0443 - acc: 0.9879 - val_loss: 0.4311 - val_acc: 0.8545
	Epoch 37/100
	20754/20754 [==============================] - 121s - loss: 0.0433 - acc: 0.9891 - val_loss: 0.4373 - val_acc: 0.8497
	Epoch 38/100
	20754/20754 [==============================] - 121s - loss: 0.0430 - acc: 0.9891 - val_loss: 0.4363 - val_acc: 0.8515
	Epoch 39/100
	20754/20754 [==============================] - 121s - loss: 0.0414 - acc: 0.9899 - val_loss: 0.4381 - val_acc: 0.8509
	Epoch 40/100
	20754/20754 [==============================] - 122s - loss: 0.0395 - acc: 0.9901 - val_loss: 0.4310 - val_acc: 0.8545
	Epoch 41/100
	20754/20754 [==============================] - 121s - loss: 0.0364 - acc: 0.9911 - val_loss: 0.4244 - val_acc: 0.8587
	Epoch 42/100
	20754/20754 [==============================] - 121s - loss: 0.0352 - acc: 0.9919 - val_loss: 0.4202 - val_acc: 0.8599
	Epoch 43/100
	20754/20754 [==============================] - 121s - loss: 0.0378 - acc: 0.9906 - val_loss: 0.4205 - val_acc: 0.8575
	Epoch 44/100
	20754/20754 [==============================] - 120s - loss: 0.0340 - acc: 0.9916 - val_loss: 0.4249 - val_acc: 0.8533
	Epoch 45/100
	20754/20754 [==============================] - 121s - loss: 0.0331 - acc: 0.9917 - val_loss: 0.4270 - val_acc: 0.8551
	Epoch 46/100
	20754/20754 [==============================] - 121s - loss: 0.0330 - acc: 0.9919 - val_loss: 0.4336 - val_acc: 0.8485
	Epoch 47/100
	20754/20754 [==============================] - 121s - loss: 0.0306 - acc: 0.9923 - val_loss: 0.4276 - val_acc: 0.8539
	Epoch 48/100
	20754/20754 [==============================] - 121s - loss: 0.0298 - acc: 0.9933 - val_loss: 0.4324 - val_acc: 0.8527
	Epoch 49/100
	20754/20754 [==============================] - 121s - loss: 0.0287 - acc: 0.9928 - val_loss: 0.4268 - val_acc: 0.8509
	Epoch 50/100
	20754/20754 [==============================] - 121s - loss: 0.0296 - acc: 0.9923 - val_loss: 0.4341 - val_acc: 0.8461
	Epoch 51/100
	20754/20754 [==============================] - 121s - loss: 0.0280 - acc: 0.9928 - val_loss: 0.4283 - val_acc: 0.8527
	Epoch 52/100
	20754/20754 [==============================] - 121s - loss: 0.0272 - acc: 0.9933 - val_loss: 0.4257 - val_acc: 0.8569
	Epoch 53/100
	20754/20754 [==============================] - 121s - loss: 0.0291 - acc: 0.9927 - val_loss: 0.4179 - val_acc: 0.8599
	Epoch 54/100
	20754/20754 [==============================] - 120s - loss: 0.0284 - acc: 0.9930 - val_loss: 0.4221 - val_acc: 0.8545
	Epoch 55/100
	20754/20754 [==============================] - 121s - loss: 0.0262 - acc: 0.9944 - val_loss: 0.4269 - val_acc: 0.8503
	Epoch 56/100
	20754/20754 [==============================] - 121s - loss: 0.0255 - acc: 0.9942 - val_loss: 0.4125 - val_acc: 0.8617
	Epoch 57/100
	20754/20754 [==============================] - 120s - loss: 0.0243 - acc: 0.9947 - val_loss: 0.4178 - val_acc: 0.8641
	Epoch 58/100
	20754/20754 [==============================] - 121s - loss: 0.0236 - acc: 0.9945 - val_loss: 0.4154 - val_acc: 0.8605
	Epoch 59/100
	20754/20754 [==============================] - 121s - loss: 0.0223 - acc: 0.9951 - val_loss: 0.4203 - val_acc: 0.8605
	Epoch 60/100
	20754/20754 [==============================] - 121s - loss: 0.0232 - acc: 0.9949 - val_loss: 0.4178 - val_acc: 0.8623
	Epoch 61/100
	20754/20754 [==============================] - 121s - loss: 0.0232 - acc: 0.9939 - val_loss: 0.4338 - val_acc: 0.8533
	Epoch 62/100
	20754/20754 [==============================] - 121s - loss: 0.0225 - acc: 0.9948 - val_loss: 0.4329 - val_acc: 0.8545
	Epoch 63/100
	20754/20754 [==============================] - 121s - loss: 0.0206 - acc: 0.9948 - val_loss: 0.4342 - val_acc: 0.8545
	Epoch 64/100
	20754/20754 [==============================] - 121s - loss: 0.0201 - acc: 0.9954 - val_loss: 0.4334 - val_acc: 0.8485
	Epoch 65/100
	20754/20754 [==============================] - 121s - loss: 0.0202 - acc: 0.9960 - val_loss: 0.4300 - val_acc: 0.8509
	Epoch 66/100
	20754/20754 [==============================] - 121s - loss: 0.0194 - acc: 0.9955 - val_loss: 0.4242 - val_acc: 0.8539
	Epoch 67/100
	20754/20754 [==============================] - 121s - loss: 0.0210 - acc: 0.9945 - val_loss: 0.4246 - val_acc: 0.8569
	1670/1670 [==============================] - 3s     
	79726/79726 [==============================] - 178s     
	Score log_loss:  0.412466302446
	Start KFold number 5 from 13
	Split train:  20586 20586
	Split valid:  1838 1838
	Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p024', 'p026', 'p035', 'p039', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p022', 'p041']
	Training keras model...
	Train on 20586 samples, validate on 1838 samples
	Epoch 1/100
	20586/20586 [==============================] - 120s - loss: 1.8180 - acc: 0.4329 - val_loss: 1.0327 - val_acc: 0.7062
	Epoch 2/100
	20586/20586 [==============================] - 120s - loss: 0.9780 - acc: 0.6730 - val_loss: 0.8168 - val_acc: 0.7639
	Epoch 3/100
	20586/20586 [==============================] - 120s - loss: 0.6689 - acc: 0.7846 - val_loss: 0.7146 - val_acc: 0.7911
	Epoch 4/100
	20586/20586 [==============================] - 120s - loss: 0.5107 - acc: 0.8375 - val_loss: 0.6398 - val_acc: 0.8128
	Epoch 5/100
	20586/20586 [==============================] - 121s - loss: 0.4113 - acc: 0.8744 - val_loss: 0.5783 - val_acc: 0.8205
	Epoch 6/100
	20586/20586 [==============================] - 120s - loss: 0.3290 - acc: 0.9010 - val_loss: 0.5201 - val_acc: 0.8466
	Epoch 7/100
	20586/20586 [==============================] - 120s - loss: 0.2776 - acc: 0.9161 - val_loss: 0.5006 - val_acc: 0.8460
	Epoch 8/100
	20586/20586 [==============================] - 120s - loss: 0.2486 - acc: 0.9253 - val_loss: 0.4726 - val_acc: 0.8569
	Epoch 9/100
	20586/20586 [==============================] - 120s - loss: 0.2168 - acc: 0.9352 - val_loss: 0.4715 - val_acc: 0.8547
	Epoch 10/100
	20586/20586 [==============================] - 120s - loss: 0.1890 - acc: 0.9455 - val_loss: 0.4556 - val_acc: 0.8580
	Epoch 11/100
	20586/20586 [==============================] - 121s - loss: 0.1724 - acc: 0.9513 - val_loss: 0.4276 - val_acc: 0.8672
	Epoch 12/100
	20586/20586 [==============================] - 120s - loss: 0.1561 - acc: 0.9560 - val_loss: 0.4276 - val_acc: 0.8624
	Epoch 13/100
	20586/20586 [==============================] - 120s - loss: 0.1428 - acc: 0.9601 - val_loss: 0.4084 - val_acc: 0.8711
	Epoch 14/100
	20586/20586 [==============================] - 120s - loss: 0.1333 - acc: 0.9631 - val_loss: 0.3992 - val_acc: 0.8711
	Epoch 15/100
	20586/20586 [==============================] - 121s - loss: 0.1225 - acc: 0.9639 - val_loss: 0.3776 - val_acc: 0.8841
	Epoch 16/100
	20586/20586 [==============================] - 120s - loss: 0.1149 - acc: 0.9668 - val_loss: 0.3850 - val_acc: 0.8743
	Epoch 17/100
	20586/20586 [==============================] - 120s - loss: 0.1047 - acc: 0.9705 - val_loss: 0.3738 - val_acc: 0.8841
	Epoch 18/100
	20586/20586 [==============================] - 120s - loss: 0.0998 - acc: 0.9719 - val_loss: 0.3586 - val_acc: 0.8857
	Epoch 19/100
	20586/20586 [==============================] - 117s - loss: 0.0965 - acc: 0.9725 - val_loss: 0.3582 - val_acc: 0.8836
	Epoch 20/100
	20586/20586 [==============================] - 116s - loss: 0.0882 - acc: 0.9763 - val_loss: 0.3451 - val_acc: 0.8879
	Epoch 21/100
	20586/20586 [==============================] - 117s - loss: 0.0823 - acc: 0.9778 - val_loss: 0.3450 - val_acc: 0.8906
	Epoch 22/100
	20586/20586 [==============================] - 116s - loss: 0.0798 - acc: 0.9790 - val_loss: 0.3437 - val_acc: 0.8906
	Epoch 23/100
	20586/20586 [==============================] - 116s - loss: 0.0763 - acc: 0.9801 - val_loss: 0.3367 - val_acc: 0.8934
	Epoch 24/100
	20586/20586 [==============================] - 116s - loss: 0.0731 - acc: 0.9797 - val_loss: 0.3378 - val_acc: 0.8901
	Epoch 25/100
	20586/20586 [==============================] - 116s - loss: 0.0667 - acc: 0.9824 - val_loss: 0.3324 - val_acc: 0.8934
	Epoch 26/100
	20586/20586 [==============================] - 116s - loss: 0.0654 - acc: 0.9826 - val_loss: 0.3226 - val_acc: 0.8966
	Epoch 27/100
	20586/20586 [==============================] - 116s - loss: 0.0592 - acc: 0.9832 - val_loss: 0.3141 - val_acc: 0.8999
	Epoch 28/100
	20586/20586 [==============================] - 116s - loss: 0.0591 - acc: 0.9839 - val_loss: 0.3158 - val_acc: 0.8988
	Epoch 29/100
	20586/20586 [==============================] - 116s - loss: 0.0579 - acc: 0.9848 - val_loss: 0.3196 - val_acc: 0.8983
	Epoch 30/100
	20586/20586 [==============================] - 116s - loss: 0.0556 - acc: 0.9849 - val_loss: 0.3140 - val_acc: 0.8993
	Epoch 31/100
	20586/20586 [==============================] - 116s - loss: 0.0527 - acc: 0.9860 - val_loss: 0.3103 - val_acc: 0.9010
	Epoch 32/100
	20586/20586 [==============================] - 116s - loss: 0.0535 - acc: 0.9856 - val_loss: 0.3093 - val_acc: 0.9032
	Epoch 33/100
	20586/20586 [==============================] - 116s - loss: 0.0514 - acc: 0.9870 - val_loss: 0.3023 - val_acc: 0.9048
	Epoch 34/100
	20586/20586 [==============================] - 116s - loss: 0.0476 - acc: 0.9874 - val_loss: 0.3114 - val_acc: 0.8999
	Epoch 35/100
	20586/20586 [==============================] - 116s - loss: 0.0456 - acc: 0.9887 - val_loss: 0.3090 - val_acc: 0.9004
	Epoch 36/100
	20586/20586 [==============================] - 116s - loss: 0.0450 - acc: 0.9877 - val_loss: 0.3103 - val_acc: 0.9004
	Epoch 37/100
	20586/20586 [==============================] - 116s - loss: 0.0422 - acc: 0.9885 - val_loss: 0.3043 - val_acc: 0.9037
	Epoch 38/100
	20586/20586 [==============================] - 116s - loss: 0.0411 - acc: 0.9892 - val_loss: 0.2960 - val_acc: 0.9053
	Epoch 39/100
	20586/20586 [==============================] - 116s - loss: 0.0406 - acc: 0.9898 - val_loss: 0.2982 - val_acc: 0.9042
	Epoch 40/100
	20586/20586 [==============================] - 117s - loss: 0.0381 - acc: 0.9904 - val_loss: 0.2939 - val_acc: 0.9064
	Epoch 41/100
	20586/20586 [==============================] - 116s - loss: 0.0367 - acc: 0.9909 - val_loss: 0.2974 - val_acc: 0.9021
	Epoch 42/100
	20586/20586 [==============================] - 117s - loss: 0.0374 - acc: 0.9899 - val_loss: 0.2789 - val_acc: 0.9124
	Epoch 43/100
	20586/20586 [==============================] - 116s - loss: 0.0377 - acc: 0.9901 - val_loss: 0.2972 - val_acc: 0.9015
	Epoch 44/100
	20586/20586 [==============================] - 116s - loss: 0.0343 - acc: 0.9913 - val_loss: 0.2873 - val_acc: 0.9059
	Epoch 45/100
	20586/20586 [==============================] - 116s - loss: 0.0320 - acc: 0.9918 - val_loss: 0.2904 - val_acc: 0.9053
	Epoch 46/100
	20586/20586 [==============================] - 116s - loss: 0.0321 - acc: 0.9912 - val_loss: 0.2888 - val_acc: 0.9048
	Epoch 47/100
	20586/20586 [==============================] - 116s - loss: 0.0328 - acc: 0.9916 - val_loss: 0.2806 - val_acc: 0.9097
	Epoch 48/100
	20586/20586 [==============================] - 116s - loss: 0.0311 - acc: 0.9924 - val_loss: 0.2790 - val_acc: 0.9091
	Epoch 49/100
	20586/20586 [==============================] - 116s - loss: 0.0302 - acc: 0.9923 - val_loss: 0.2771 - val_acc: 0.9102
	Epoch 50/100
	20586/20586 [==============================] - 116s - loss: 0.0289 - acc: 0.9926 - val_loss: 0.2765 - val_acc: 0.9086
	Epoch 51/100
	20586/20586 [==============================] - 116s - loss: 0.0287 - acc: 0.9926 - val_loss: 0.2760 - val_acc: 0.9102
	Epoch 52/100
	20586/20586 [==============================] - 117s - loss: 0.0275 - acc: 0.9936 - val_loss: 0.2733 - val_acc: 0.9102
	Epoch 53/100
	20586/20586 [==============================] - 116s - loss: 0.0273 - acc: 0.9927 - val_loss: 0.2784 - val_acc: 0.9075
	Epoch 54/100
	20586/20586 [==============================] - 116s - loss: 0.0269 - acc: 0.9934 - val_loss: 0.2805 - val_acc: 0.9059
	Epoch 55/100
	20586/20586 [==============================] - 117s - loss: 0.0247 - acc: 0.9942 - val_loss: 0.2677 - val_acc: 0.9108
	Epoch 56/100
	20586/20586 [==============================] - 117s - loss: 0.0249 - acc: 0.9940 - val_loss: 0.2617 - val_acc: 0.9140
	Epoch 57/100
	20586/20586 [==============================] - 116s - loss: 0.0233 - acc: 0.9947 - val_loss: 0.2752 - val_acc: 0.9086
	Epoch 58/100
	20586/20586 [==============================] - 116s - loss: 0.0222 - acc: 0.9943 - val_loss: 0.2766 - val_acc: 0.9081
	Epoch 59/100
	20586/20586 [==============================] - 117s - loss: 0.0243 - acc: 0.9939 - val_loss: 0.2594 - val_acc: 0.9146
	Epoch 60/100
	20586/20586 [==============================] - 117s - loss: 0.0231 - acc: 0.9941 - val_loss: 0.2551 - val_acc: 0.9178
	Epoch 61/100
	20586/20586 [==============================] - 116s - loss: 0.0219 - acc: 0.9949 - val_loss: 0.2625 - val_acc: 0.9124
	Epoch 62/100
	20586/20586 [==============================] - 116s - loss: 0.0210 - acc: 0.9952 - val_loss: 0.2695 - val_acc: 0.9086
	Epoch 63/100
	20586/20586 [==============================] - 116s - loss: 0.0215 - acc: 0.9945 - val_loss: 0.2562 - val_acc: 0.9135
	Epoch 64/100
	20586/20586 [==============================] - 116s - loss: 0.0213 - acc: 0.9949 - val_loss: 0.2678 - val_acc: 0.9070
	Epoch 65/100
	20586/20586 [==============================] - 116s - loss: 0.0207 - acc: 0.9946 - val_loss: 0.2635 - val_acc: 0.9102
	Epoch 66/100
	20586/20586 [==============================] - 117s - loss: 0.0209 - acc: 0.9953 - val_loss: 0.2627 - val_acc: 0.9108
	Epoch 67/100
	20586/20586 [==============================] - 117s - loss: 0.0203 - acc: 0.9956 - val_loss: 0.2567 - val_acc: 0.9173
	Epoch 68/100
	20586/20586 [==============================] - 117s - loss: 0.0199 - acc: 0.9951 - val_loss: 0.2702 - val_acc: 0.9059
	Epoch 69/100
	20586/20586 [==============================] - 117s - loss: 0.0196 - acc: 0.9954 - val_loss: 0.2818 - val_acc: 0.8988
	Epoch 70/100
	20586/20586 [==============================] - 117s - loss: 0.0193 - acc: 0.9952 - val_loss: 0.2677 - val_acc: 0.9119
	Epoch 71/100
	20586/20586 [==============================] - 117s - loss: 0.0192 - acc: 0.9958 - val_loss: 0.2713 - val_acc: 0.9075
	1838/1838 [==============================] - 4s     
	79726/79726 [==============================] - 177s     
	Score log_loss:  0.255138842735
	Start KFold number 6 from 13
	Split train:  20825 20825
	Split valid:  1599 1599
	Train drivers:  ['p002', 'p012', 'p014', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p015', 'p045']
	Training keras model...
	Train on 20825 samples, validate on 1599 samples
	Epoch 1/100
	20825/20825 [==============================] - 118s - loss: 1.7141 - acc: 0.4645 - val_loss: 0.9815 - val_acc: 0.6929
	Epoch 2/100
	20825/20825 [==============================] - 119s - loss: 0.8958 - acc: 0.7019 - val_loss: 0.9185 - val_acc: 0.6754
	Epoch 3/100
	20825/20825 [==============================] - 118s - loss: 0.6050 - acc: 0.8058 - val_loss: 0.8893 - val_acc: 0.6798
	Epoch 4/100
	20825/20825 [==============================] - 118s - loss: 0.4647 - acc: 0.8499 - val_loss: 0.9247 - val_acc: 0.6673
	Epoch 5/100
	20825/20825 [==============================] - 118s - loss: 0.3625 - acc: 0.8882 - val_loss: 0.9493 - val_acc: 0.6592
	Epoch 6/100
	20825/20825 [==============================] - 119s - loss: 0.2977 - acc: 0.9101 - val_loss: 0.9777 - val_acc: 0.6585
	Epoch 7/100
	20825/20825 [==============================] - 118s - loss: 0.2501 - acc: 0.9252 - val_loss: 0.9837 - val_acc: 0.6554
	Epoch 8/100
	20825/20825 [==============================] - 119s - loss: 0.2261 - acc: 0.9320 - val_loss: 1.0249 - val_acc: 0.6510
	Epoch 9/100
	20825/20825 [==============================] - 119s - loss: 0.1938 - acc: 0.9435 - val_loss: 1.0381 - val_acc: 0.6510
	Epoch 10/100
	20825/20825 [==============================] - 119s - loss: 0.1734 - acc: 0.9514 - val_loss: 1.0618 - val_acc: 0.6498
	Epoch 11/100
	20825/20825 [==============================] - 118s - loss: 0.1592 - acc: 0.9528 - val_loss: 1.0874 - val_acc: 0.6442
	Epoch 12/100
	20825/20825 [==============================] - 119s - loss: 0.1428 - acc: 0.9595 - val_loss: 1.0995 - val_acc: 0.6454
	Epoch 13/100
	20825/20825 [==============================] - 119s - loss: 0.1280 - acc: 0.9647 - val_loss: 1.1077 - val_acc: 0.6442
	Epoch 14/100
	20825/20825 [==============================] - 119s - loss: 0.1184 - acc: 0.9661 - val_loss: 1.1314 - val_acc: 0.6385
	1599/1599 [==============================] - 3s     
	79726/79726 [==============================] - 177s     
	Score log_loss:  0.889345869747
	Start KFold number 7 from 13
	Split train:  20335 20335
	Split valid:  2089 2089
	Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
	Test drivers:  ['p016', 'p049']
	Training keras model...
	Train on 20335 samples, validate on 2089 samples
"""

folds = s.split('Start KFold')
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']
for i, fold in enumerate(folds):
	print('processing fold %d' % i)
	lines = fold.split('\n')

	loss_lines = list(filter(lambda x: 'val_loss:' in x, lines))

	# print('\n'.join(lines))

	train_losses = list(map(lambda line: float(line.split(' ')[-10]), loss_lines))
	valid_losses = list(map(lambda line: float(line.split(' ')[-4]), loss_lines))

	train_acc = list(map(lambda line: float(line.split(' ')[-7]), loss_lines))
	valid_acc = list(map(lambda line: float(line.split(' ')[-1]), loss_lines))



	if len(train_losses) > 0 and i == 2:
		# fold_name = fold.split(' ')[2]
		fold_name = list(filter(lambda line: 'Test drivers' in line, lines))[0].split(': ')[-1].strip().strip('[').strip(']').replace("'", '')

		pylab.subplot(211)
		pylab.plot(train_losses, '--' + colors[i % len(colors)], label=str(fold_name))
		pylab.plot(valid_losses, colors[i % len(colors)])

		pylab.subplot(212)
		pylab.plot(train_acc, '--' + colors[i % len(colors)], label='train %s' % fold_name)
		pylab.plot(valid_acc, colors[i % len(colors)], label='valid %s' % fold_name)
	else:
		print('no data')


pylab.subplot(211)
pylab.legend()
pylab.grid(True)

pylab.subplot(212)
pylab.grid(True)

pylab.show()