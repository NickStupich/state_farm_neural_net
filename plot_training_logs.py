import numpy as np
import pylab

if 1:
	s = """Epoch 1/50
	11188/11188 [==============================] - 87s - loss: 3.2601 - val_loss: 2.3139
	Epoch 2/50
	11188/11188 [==============================] - 88s - loss: 2.2963 - val_loss: 2.1288
	Epoch 3/50
	11188/11188 [==============================] - 88s - loss: 1.8754 - val_loss: 1.9958
	Epoch 4/50
	11188/11188 [==============================] - 88s - loss: 1.5844 - val_loss: 1.8970
	Epoch 5/50
	11188/11188 [==============================] - 88s - loss: 1.3560 - val_loss: 1.8088
	Epoch 6/50
	11188/11188 [==============================] - 88s - loss: 1.1778 - val_loss: 1.7359
	Epoch 7/50
	11188/11188 [==============================] - 88s - loss: 1.0213 - val_loss: 1.6810
	Epoch 8/50
	11188/11188 [==============================] - 88s - loss: 0.9165 - val_loss: 1.6331
	Epoch 9/50
	11188/11188 [==============================] - 88s - loss: 0.8043 - val_loss: 1.5959
	Epoch 10/50
	11188/11188 [==============================] - 88s - loss: 0.7222 - val_loss: 1.5591
	Epoch 11/50
	11188/11188 [==============================] - 89s - loss: 0.6413 - val_loss: 1.5329
	Epoch 12/50
	11188/11188 [==============================] - 88s - loss: 0.5825 - val_loss: 1.5124
	Epoch 13/50
	11188/11188 [==============================] - 89s - loss: 0.5190 - val_loss: 1.5008
	Epoch 14/50
	11188/11188 [==============================] - 89s - loss: 0.4863 - val_loss: 1.4809
	Epoch 15/50
	11188/11188 [==============================] - 89s - loss: 0.4402 - val_loss: 1.4786
	Epoch 16/50
	11188/11188 [==============================] - 89s - loss: 0.4215 - val_loss: 1.4630
	Epoch 17/50
	11188/11188 [==============================] - 88s - loss: 0.3899 - val_loss: 1.4472
	Epoch 18/50
	11188/11188 [==============================] - 89s - loss: 0.3643 - val_loss: 1.4391
	Epoch 19/50
	11188/11188 [==============================] - 89s - loss: 0.3376 - val_loss: 1.4321
	Epoch 20/50
	11188/11188 [==============================] - 89s - loss: 0.3191 - val_loss: 1.4220
	Epoch 21/50
	11188/11188 [==============================] - 89s - loss: 0.3015 - val_loss: 1.4107
	Epoch 22/50
	11188/11188 [==============================] - 88s - loss: 0.2830 - val_loss: 1.4112
	Epoch 23/50
	11188/11188 [==============================] - 89s - loss: 0.2712 - val_loss: 1.4014
	Epoch 24/50
	11188/11188 [==============================] - 88s - loss: 0.2600 - val_loss: 1.4202
	Epoch 25/50
	11188/11188 [==============================] - 88s - loss: 0.2416 - val_loss: 1.4128
	Epoch 26/50
	11188/11188 [==============================] - 88s - loss: 0.2314 - val_loss: 1.4068
	Epoch 27/50
	11188/11188 [==============================] - 88s - loss: 0.2218 - val_loss: 1.4105
	Epoch 28/50
	11188/11188 [==============================] - 89s - loss: 0.2134 - val_loss: 1.3967
	Epoch 29/50
	11188/11188 [==============================] - 89s - loss: 0.2042 - val_loss: 1.4058
	Epoch 30/50
	11188/11188 [==============================] - 88s - loss: 0.1911 - val_loss: 1.4067
	Epoch 31/50
	11188/11188 [==============================] - 90s - loss: 0.1862 - val_loss: 1.3993
	Epoch 32/50
	11188/11188 [==============================] - 88s - loss: 0.1765 - val_loss: 1.4016
	Epoch 33/50
	11188/11188 [==============================] - 88s - loss: 0.1725 - val_loss: 1.4108
	Epoch 34/50
	11188/11188 [==============================] - 87s - loss: 0.1685 - val_loss: 1.4052
	Epoch 35/50
	11188/11188 [==============================] - 88s - loss: 0.1599 - val_loss: 1.4073
	Epoch 36/50
	11188/11188 [==============================] - 88s - loss: 0.1604 - val_loss: 1.4032
	Epoch 37/50
	11188/11188 [==============================] - 88s - loss: 0.1468 - val_loss: 1.4105
	Epoch 38/50
	11188/11188 [==============================] - 88s - loss: 0.1486 - val_loss: 1.4114
	Epoch 39/50
	11188/11188 [==============================] - 89s - loss: 0.1441 - val_loss: 1.4083
	Epoch 40/50
	11188/11188 [==============================] - 88s - loss: 0.1379 - val_loss: 1.4106
	Epoch 41/50
	11188/11188 [==============================] - 88s - loss: 0.1412 - val_loss: 1.4143
	Epoch 42/50
	11188/11188 [==============================] - 88s - loss: 0.1304 - val_loss: 1.4093
	Epoch 43/50
	11188/11188 [==============================] - 88s - loss: 0.1268 - val_loss: 1.4207
	Epoch 44/50
	11188/11188 [==============================] - 88s - loss: 0.1217 - val_loss: 1.4169
	Epoch 45/50
	11188/11188 [==============================] - 88s - loss: 0.1246 - val_loss: 1.4169
	Epoch 46/50
	11188/11188 [==============================] - 88s - loss: 0.1236 - val_loss: 1.4206
	Epoch 47/50
	11188/11188 [==============================] - 88s - loss: 0.1130 - val_loss: 1.4215
	Epoch 48/50
	11188/11188 [==============================] - 88s - loss: 0.1174 - val_loss: 1.4226
	Epoch 49/50
	11188/11188 [==============================] - 88s - loss: 0.1094 - val_loss: 1.4137
	Epoch 50/50
	11188/11188 [==============================] - 89s - loss: 0.1083 - val_loss: 1.4174
	"""

"""Epoch 1/50
11188/11188 [==============================] - 87s - loss: 3.2601 - val_loss: 2.3139
Epoch 2/50
11188/11188 [==============================] - 88s - loss: 2.2963 - val_loss: 2.1288
Epoch 3/50
11188/11188 [==============================] - 88s - loss: 1.8754 - val_loss: 1.9958
"""
lines = s.split('\n')

lines = list(filter(lambda x: 'loss' in x, lines))
train_losses = list(map(lambda line: float(line.split(' ')[-4]), lines))
valid_losses = list(map(lambda line: float(line.split(' ')[-1]), lines))

pylab.plot(train_losses, label='training')
pylab.plot(valid_losses, label='validation')
pylab.legend()
pylab.grid(True)
pylab.show()